 #+hugo_base_dir: /home/gtpedrosa/Projects/blog/hugo-blog/

* blog
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
** DONE Using org mode and ox-hugo to replace markdown in hugo workflow
CLOSED: [2019-01-13 dom 13:41]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-01-using-org-mode-and-ox-hugo-to-replace-markdown-in-hugo-workflow
:END:

I have decided to give org mode blogging a go. Why org mode? The main reasons for this were:

- Abandon markdown: I always get confused by markdown markup choices. I find myself constantly reaching for [[https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet][markdown cheatsheet]] to find out how to insert a link. "Is it parenthesis or brackets?" gets me every time;
- Increase familiarity with org mode synthax to use it in my literary programming workflows in the near future (tangle+babel);
- Reduce friction to create new blog posts using the great [[https://ox-hugo.scripter.co/][ox-hugo]] by Kaushal Modi.

For anyone trying to do the same, I recommend:

- [[https://www.kengrimes.com/ox-hugo-tutorial/][ox-hugo tutorial by Ken Grimes]]
- [[https://ox-hugo.scripter.co/][ox-hugo website/manual]]
- [[https://karl-voit.at/2017/09/23/orgmode-as-markup-only/][Some org mode markup notes and comments by Karl Voigt]]
- [[http://ergoemacs.org/emacs/emacs_org_markup.html][Most frequently used org mode markup by Xah]]

Since I want this post to be self contained for further reference in the near future, I will summarise what I've learned from the references above.

*** Installation and .emacs setup

#+begin_quote
*EDIT Apr 04 2020:* Instructions updated after noticing they failed in brand new system installation
#+end_quote

- Installation with package manager: 
#+BEGIN_SRC emacs-lisp
M-x package-install RET ox-hugo RET
#+END_SRC
- Require it in the .emacs file:
#+BEGIN_SRC org
(with-eval-after-load 'ox__
  (require 'ox-hugo))
#+END_SRC
- To take advantage of auto exporting on save I added the following to my .emacs file:
#+BEGIN_SRC org
;; Hugo orgmode exporter
(require 'org-hugo-auto-export-mode) ;If you want the auto-exporting on file saves
#+END_SRC
- Enable snippets shortcuts
#+begin_src org
(require 'org-tempo);Enable snippets expantions (ex: <s+TAB or <q+TAB)
#+end_src
- Now to create a capture template to create new blog postos on the fly:
#+BEGIN_SRC org
;; Populates only the EXPORT_FILE_NAME property in the inserted headline.
(with-eval-after-load 'org-capture
  (defun org-hugo-new-subtree-post-capture-template ()
    "Returns `org-capture' template string for new Hugo post.
See `org-capture-templates' for more information."
    (let* ((title (read-from-minibuffer "Post Title: ")) ;Prompt to enter the post title
           (fname (org-hugo-slug title)))
      (mapconcat #'identity
                 `(
                   ,(concat "* TODO " title)
                   ":PROPERTIES:"
                   ,(concat ":EXPORT_FILE_NAME: " (format-time-string "%Y-%m-%d-") fname)
                   ":END:"
                   "%?\n")          ;Place the cursor here finally
                 "\n"))))

;; org capture templates
(setq org-capture-templates
 '(
   ("h"                ;`org-capture' binding + h
                    "Hugo post"
                    entry
                    ;; It is assumed that below file is present in `org-directory'
                    ;; and that it has a "Blog Ideas" heading. It can even be a
                    ;; symlink pointing to the actual location of all-posts.org!
                    (file+olp "/home/guilherme/blog/content-org/posts.org" "blog")
                    (function org-hugo-new-subtree-post-capture-template))
))
#+END_SRC
- Include a /.dir-locals.el/ file in the project root, assuming all org-files are in a /content-org/ directory below root:
#+begin_src org
(("content-org/"
  . ((org-mode . ((eval . (org-hugo-auto-export-mode)))))))
#+end_src

*Note:* everything here so far is in the manual. I only added the current date to the file name being created in the ~EXPORT_FILE_NAME:~ property to be consistent with my previous naming scheme.

*** Org file structure

Ken grimes did a great job explaining how to use one org file to organize a hugo blog. I'll just mention a few things. First of all, Hugo has a contents folder and depending on the theme you use (I use cocoa) it will have 

#+BEGIN_SRC shell :exports both :results output
  tree -d -L 2 ../content
#+END_SRC

#+RESULTS:
: ../content
: ├── about
: ├── blog
: └── projects
: 
: 3 directories

I haven't been using ox-hugo in my previous posts, so I already have markdown files that do not have a corresponding org version. However, my posts reside in the blog folder. As an example, a minimal org file used to generate this post would be the following:

#+begin_src org
#+hugo_base_dir: /home/guilherme/blog/
 * blog
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
 ** TODO Using org mode and ox-hugo to replace markdown in hugo workflow
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-01-using-org-mode-and-ox-hugo-to-replace-markdown-in-hugo-workflow
:END:

 * Footnotes
 * COMMENT Local Variables                          :ARCHIVE:
 # Local Variables:
 # org-hugo-auto-export-on-save: t
 # End:
#+end_src

The local variable ~org-hugo-auto-export-on-save~ with the ARCHIVE tag enables hugo auto export to my blog's master org file only.

*** Workflow

To create a new blog post I simply issue ~C+c C+c + h~ and a title for my new post is prompted. Along with it the filename with date are already set by the property in the capture template. Form now on I just write. 

To view any changes on my working post:

#+BEGIN_SRC bash
hugo serve -D --navigateToChanged
#+END_SRC

When done with the post, just changing the task from TODO to DONE will create a special property date that will be the post's date published.

*** Markup examples
I've put together some markup examples that were spread through the sources mentioned in the beggining of the post. These are for quick lookups, where I can find the synthax for features I use the most.

#+caption: Same Org Logo
#+name: img__org_logo
[[/home/gtpedrosa/Projects/blog/hugo-blog/static/img/gnu-unicorn.png]]
*Here we refer to [[img__org_logo]].*

 #+BEGIN_QUOTE
 Everything should be made as simple as possible,
 but not any simpler -- Albert Einstein
 #+END_QUOTE

#+BEGIN_SRC org
 * This Is A Heading
 ** This Is A Sub-Heading
 *** And A Sub-Sub-Heading

 Paragraphs are separated by at least one empty line.

 *bold* /italic/ _underlined_ +strikethrough+ =monospaced= ~code~
 [[http://Karl-Voit.at][Link description]]
 http://Karl-Voit.at → link without description

 : Simple pre-formatted text such as for source code.
 : This also respects the line breaks. *bold* is not bold here.

 - list item
 - another item
   - sub-item
     1. also enumerated
     2. if you like
 - [ ] yet to be done
 - [X] item which is done	
#+END_SRC

#+caption: Hello
#+name: code__hello
#+begin_src emacs-lisp
(message "Hello")
#+end_src
*Here we refer to [[code__helloagain]].*

#+include: "./common.org::#lorem-ipsum" :only-contents t

#+caption: Hello Again
#+name: code__helloagain
#+begin_src emacs-lisp
(message "Hello again")
#+end_src
*Here we refer to [[code__hello]].*
** DONE Generating documentation of Matlab scripts automatically with mkdocs
CLOSED: [2019-01-20 dom 23:06]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-20-generating-documentation-of-matlab-scripts-automatically-with-mkdocs
:END:

Something that always called my attention is how much more documented and even appealing to newcomers projects in python or R are if compared to Matlab in general. One exception is [[https://github.com/vlfeat/matconvnet][MatConvNet]], a library that implements convolutional neural networks (CNNs) in Matlab and has a good looking and helpful documentation. 

The documentation stands out as it is produced with [[https://www.mkdocs.org/][MkDocs]], a static site generator based on markdown specific for project documentation. Something very different from Matlab's default html help template. But why bother adding another layer of complexity writing markdown files for the documentation? Why not use the source code itself? The authors of MatConvNet created a parser capable of extracting the comments of the functions in mfiles and auto generate the markdown necessary for MkDocs. The python scripts ~matdoc.py~ and ~matdocparser.py~ do exactly that. I must acknowledge it is copywrited material (Copyright (c) 2014-16 The MatConvNet Team) and not made by me.

For the remaining of this post consider a simple project composed of two mfiles: ~addme.m~ and ~subtractme.m~ which do exactly what you would expect from them, add and subtract two numbers. Also consider a ~index.md~ and a ~mkdocs.yml~ file, the bare minimum for a MkDocs documentation. This is the files setup and they can be downloaded from my github [[https://github.com/gtpedrosa/matlab-mkdocs][here]].

#+begin_src shell :exports both :results output
tree -L 2 ~/Sandbox/docs
#+end_src

#+RESULTS:
#+begin_example
/home/guilherme/Sandbox/docs
├── addme.m
├── COPYING
├── COPYING~
├── docs
│   └── index.md
├── makefile
├── matdocparser.py
├── matdocparser.pyc
├── matdoc.py
├── mkdocs.yml
└── subtractme.m

1 directory, 10 files
#+end_example

The following make file is responsible for the automation of the pocess:

#+begin_src shell
PYTHON = python2
MKDOCS = mkdocs
SRC = $(wildcard *.m)
TAR = $(SRC:.m=.md)

mfiledir = docs/mfiles

$(info SRC is $(SRC))
$(info TAR is $(TAR))
$(info mfiledir is $(mfiledir))

.PHONY: all clean

all: $(TAR)

%.md: %.m matdoc.py matdocparser.py
	$(info $(@))
	$(info $(@D))
	mkdir -p $(mfiledir)
	$(PYTHON) ./matdoc.py "$(<)" > "$(mfiledir)/$(@)"

doc-serve: mkdocs.yml
	$(MKDOCS) serve

clean:
	rm -f $(TAR)
	rm -rf $(mfiledir)
#+end_src

Issuing 

#+begin_src shell
make all
make doc-serve
#+end_src

This is the expected output:

#+RESULTS:
#+begin_example
SRC is subtractme.m addme.m
TAR is subtractme.md addme.md
mfiledir is docs/mfiles
subtractme.md
.
mkdir -p docs/mfiles
python2 ./matdoc.py "subtractme.m" > "docs/mfiles/subtractme.md"
addme.md
.
mkdir -p docs/mfiles
python2 ./matdoc.py "addme.m" > "docs/mfiles/addme.md"
SRC is subtractme.m addme.m
TAR is subtractme.md addme.md
mfiledir is docs/mfiles

INFO    -  Building documentation... 
INFO    -  Cleaning site directory 
[I 190120 22:44:13 server:283] Serving on http://127.0.0.1:8000
[I 190120 22:44:13 handlers:60] Start watching changes
[I 190120 22:44:13 handlers:62] Start detecting changes
[I 190120 22:44:55 handlers:133] Browser Connected: http://localhost:8000/#project-layout
[I 190120 22:44:55 handlers:133] Browser Connected: http://127.0.0.1:8000/

#+end_example

And finally, the end result, a home page based on the ~index.md~ file:

#+caption: MkDocs documentation generated automatically for a matlab project
#+name: mkdocsproject
[[/home/guilherme/blog/static/img/mkdocshome.png]]

And more importantly, automatic documentation for each function in a specific menu called ~M-files~:

#+caption: Documentation for each mfile
#+name: mkdocsfunctions
[[/home/guilherme/blog/static/img/mkdocsfunction.png]]

** DONE Using httr with JSON API's                                  :R:APIs:
CLOSED: [2019-03-24 dom 11:35]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-03-24-using-httr-with-json-api-s
:END:

It is incredbly easy to make R interact with external API's. I've found [[https://cran.r-project.org/web/packages/httr/vignettes/api-packages.html][the httr vignette]] to be a great resource on how to make a wrapper to interact with them. However I've stumbled in one quirk that is worth mentioning.

While creating a body to a POST request message, encoded with json, I verified that my requests were being turned down by the server. The issue was related  to a behavior of the ~jsonlite~ package, one of httr's dependencies which uses  ~auto_unbox=TRUE~ by default. This isn't an issue /per se/ but for length one vector jsonlite returned:

#+BEGIN_SRC R :exports both :results output
cat(jsonlite:::toJSON(list(message = "my string"),auto_unbox=T))
#+END_SRC

#+RESULTS:
: {"message":"my string"}

Whereas the API requested a *boxed* response from length one vectors, such the one you get without the ~auto_unbox=TRUE~ option

#+BEGIN_SRC R :exports both :results output
cat(jsonlite:::toJSON(list(message = "my string")))
#+END_SRC

#+RESULTS:
: {"message":["my string"]}

Reading [[https://github.com/r-lib/httr/issues/159][this github issue]] might give a more in depth explanation.

This led me to rabbit holes such as forking ~httr~ and recompiling with ~auto_unbox=FALSE~ option, which I did. But not without breaking other requests which truly needed to be unboxed.

The solution was simpler than I thought and makes use of the function ~AsIs~ from the base package. It can be called with the ~I(x)~ synthax and changes the class of an object indicating it should be treated /as is/. What this does is to prevent the ~auto_unbox~ behavior on certain fields where this is undesirable, such as in the following example: 

#+BEGIN_SRC R :exports both :results output
cat(jsonlite:::toJSON(list(message = "my string",mymessage = I("My other string")),auto_unbox=T))
#+END_SRC

#+RESULTS:
: {"message":"my string","mymessage":["My other string"]}

This approach not only did not break anything but also made my requests compatible with the server boxed length one vectors specification as required.
** DONE Using SQLAlchemy to navigate an existing database :python:ORM:Databases:
CLOSED: [2019-04-06 sáb 18:56]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-04-06-using-sqlalchemy-to-navigate-an-existing-database
:END:

Given the task to interact with an existing database I felt compelled to use the ORM abstraction instead of making queries with raw sql. My aim was to avoid the common pitfalls regarding making text templates for sqlqueries, prone to sql injection exploits, and enhance query composability. 

I've found there are essentialy two ways to approach this task: through reflextion or a declarative model. Both approaches are explained in the following sections.

*** SQLAlchemy reflection

Reflection uses metadata property to access schema constructs. It offers a few methods to access table objects, which do not have to be explicitly declared. 

The downside of this approach is mantainability, since schema changes can make code unreliable. Here's an eample of how to access the /TimeStamp/ column of a /Table_I_Want_to_Interact/ in a generic database:

#+BEGIN_SRC python
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine, MetaData, Table

# Using SQLAlchemy reflection example
engine = create_engine('connectionstringhere')
table1meta = MetaData(engine)
table1 = Table('Table_I_Want_to_Interact', table1meta, autoload=True)
DBSession = sessionmaker(bind=engine)
session = DBSession()
results = session.query(table1).filter(table1.columns.TimeStamp>="2019-02-26 18:00:00.000")
results.all()
#+END_SRC

*** SQLAlchemy declarative model

The declarative model needs Table objects to be explicitly declared. Due to this inherent verbose nature, I have found it is easier to grasp what is happening and even how the database is structured after a glance at the source code, such as in the following snippet:

#+BEGIN_SRC python
from sqlalchemy import create_engine, MetaData, BigInteger, CHAR, Column, DateTime, Float, Integer, SmallInteger, String, Table, Unicode, text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()
metadata = Base.metadata


my_table_object = Table(
    'table_name', metadata,
    Column('Column1', Integer, nullable=False),
    Column('TimeStamp', DateTime, nullable=False),
    Column('Column3', Integer, nullable=False),
    Column('Column4', Unicode(2000))
)

#+END_SRC

Here a table named /table_name/ in the database is being mapped to the /my_table_object/ instance. It should be noted that not all columns need to be mapped. Uninteresting columns can be left out with no drawbacks.

Depending on the database structure size, however,  it could be cumbersome to define multiple tables. For use cases like this, I have found the package [[https://pypi.org/project/sqlacodegen/][sqlacodegen]] of great help. It automates the task of creating the declarative models for you. Providing an output file and a connections tring it is as easy as issuing:

#+BEGIN_SRC shell
sqlcodegen --outfile models.py mssql+pyodbc......
#+END_SRC

The resulting file can be easily imported and the this task promptly abstracted.

** DONE Reading SQL Dumps with SQL Server management Studio :sql:Databases:
CLOSED: [2020-04-12 dom 10:58]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-04-05-reading-sql-dumps-with-sql-management-studio
:END:

This post is about how to inspect the content of SQL database (/.mdf/ and /.ldf/ files). The answer is to attach these files to an existing SQL server instance, instead of opening them directly with a tool such as SQL Management Studio. This was not clear time until I stumbled upon [[https://www.youtube.com/watch?v=rhIr9Qf-oHw][this video.]]

*** Steps

1. Keep a SQL Server instance running in the background;
2. Fire up SQL Management studio and connect to this instance by providing /.\SQLEXPRESS/ in the "Server name" field;
3. Right click "Database" and attach the mdf file. The ldf is automatically included;

*** Attention points

To check #1 spin up /SQL Configuration Manager/ and look for **SQL Server
(SQLEXPRESS)** instance. It should be already running by default, as shown in
Figure 1.

#+caption: SQL Express running instance
#+name: img:sqlexpress
#+label: img:sqlexpress
[[/home/gtpedrosa/Projects/blog/hugo-blog/static/img/sqlexpress.png]]

As for #2 make sure to login using the system credentials as shown in Figure 2.

#+caption: SQL Server login
#+name: img:sqlserver
#+label: img:sqlserver
[[/home/gtpedrosa/Projects/blog/hugo-blog/static/img/sqlserver.png]]

As for #3, if you are not admin the mdf file needs to be stored somewhere in the
 Public user profile so the SQLExpress instance is able to locate it.

** DONE Building Emacs from source :emacs:source:
CLOSED: [2020-04-11 sáb 10:59]
:PROPERTIES: 
:EXPORT_FILE_NAME: 2020-04-10-building-emacs-from-source-instructions
:END:

Steps needed to install emacs locally, mantaining pre-existing installation intact. In the end you will two different versions of emacs running in your system.

- [[https://www.emacswiki.org/emacs/EmacsSnapshotAndDebian][Install dependencies:]]
#+begin_src bash
sudo apt-get install autoconf automake libtool texinfo build-essential xorg-dev libgtk-3-dev libjpeg-dev libncurses5-dev libdbus-1-dev libgif-dev libtiff-dev libm17n-dev libpng-dev librsvg2-dev libotf-dev libgnutls28-dev libxml2-dev libxpm-dev
#+end_src
- [[https://www.gnu.org/software/emacs/download.html][Download emacs from a nearby mirror]]
- Extract downloaded file. In this case it is /emacs-26.3.tar.xz/, and go to the extracted folder:
#+begin_src bash
cd ~/Downloads
tar -xf emacs-26.3.tar.xz
cd emacs-26.3.tar.xz
#+end_src
- Run /configure/ setting the prefix to the local folder in home directory:
#+begin_src bash
./configure --with-mailutils --prefix="${HOME}/local"
#+end_src
- Build the components and istall it:
#+begin_src bash
make
make install
#+end_src

To run it, issue:
#+begin_src bash
/home/local/bin/emacs
#+end_src

The local installation, if any, should still work normally.

** DONE Upgrading an outdated Hugo template :hugo:
CLOSED: [2020-05-10 dom 18:04]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-05-10-upgrading-an-outdated-hugo-template
:END:

Recently, I wanted to restart blogging in a new machine. After installing the
latest hugo version at the time and pulling my git repo I soon realized:

1. Hugo version in which the blog was built was v0.31, whereas the current one
   was v0.68.1.
2. The cocoa development was abandonned and no updates were made to cope with
   hugo enhancements

Since I do like this theme and already had a fork of it I decided to try and
upgrade it by myself, even though I have no experience with the go programming
language or web development.

This post is to tell you how I went about it.

*** Finding where the errors come from

First of all, running the dated theme with new hugo raised the following errors:

#+caption: Running hugo serve on outdated template
#+name: oldtemplate
[[/home/gtpedrosa/Projects/blog/hugo-blog/static/img/hugo-warnings.png]]
*Hugo serve warnings on outdated template*

The first thing you may notice is that there is no mention to what part of the
template is raising the warnings being shown. To overcome this, I grepped the
offending structures and mapped which template files were triggering the
warnings:

#+caption: Finding out offending lines from hugo template
#+name: greptemplate
[[/home/gtpedrosa/Projects/blog/hugo-blog/static/img/hugo-warning-lines.png]]
*Hugo warning files and lines*

Just in case you are wondering here is a summary of the grep flags used:

- r or -R is recursive,
- n is line number, and
- w stands for match the whole word.

The next step involved fiddling with the source code and learning about each one of the errors.

*** Page.RSSLink is deprecated

I have found some github issues related to the matter, such as [[https://github.com/gohugoio/hugo/issues/4427][this one.]]
However, what solved my issue was to read the docs [[https://gohugo.io/templates/rss/][here]] and look how an up to dated
template should handle RSS. Replacing the bit using the /.RSSLink/ construct
with the snippet below solved the issue.

#+BEGIN_SRC html
{{ with .OutputFormats.Get "rss" -}}
    {{ printf `<link rel="%s" type="%s" href="%s" title="%s" />` .Rel .MediaType.Type .Permalink $.Site.Title | safeHTML }}
{{ end -}}
#+END_SRC

*** Page.URL is deprecated

This error was easier to tackle. The warning gave a reasonable solution that
worked in my case. By replacing /Page.URL/ with /.Permalink/ everything worked
as expected. Note that there was some trial and error here since there are other
two other possible options according to the warning. I iterated until success.

*** Page.UniqueID is deprecated

Again the warning suggestion was spot on and replacing /.UniqueID/ with
/.File.UniqueID/ supressed the warning.

*** Most recent blog posts not showing on index.html

This was the trickiest to fix. I ended up reading a little bit about [[https://gohugo.io/templates/template-debugging/][how to
debug hugo templates.]] It so happens that after a couple of iterations printing
some of the variables in the /index.html/ file with the synthax

#+BEGIN_SRC html
{{ printf "%#v" .Permalink }}
#+END_SRC

I found out /.Data.Pages/ as not yielding the right ammount of posts.
Using /.Site.RegularPages/ did. I cannot find the exact resource which brought to
my attention the difference between the old and new hugo synthax, however, It is
agreeable that /.Data/ is too generic of a name for this use case.

*** Final result

As final result the theme is working without any warnings on hugo v0.68.1.

The changes applied to the theme are summarised by the git diff below. For more
reasonable view just check [[https://github.com/gtpedrosa/cocoa-hugo-theme][my fork of the cocoa-hugo theme.]]

#+BEGIN_SRC shell :results output
cd /home/gtpedrosa/Projects/blog/hugo-blog/themes/cocoa/
git diff c6e7 434d
#+END_SRC

#+BEGIN_SRC shell
diff --git a/layouts/_default/list.html b/layouts/_default/list.html
index b2348a1..4490e6c 100644
--- a/layouts/_default/list.html
+++ b/layouts/_default/list.html
@@ -10,7 +10,7 @@
             <nav class="section-items">
                 <ul>
                 {{ range .ByWeight }}
-                    <li><a {{ printf "href=%q" .URL | safeHTMLAttr }}>{{ default .Title .Params.heading }}</a></li>
+                    <li><a {{ printf "href=%q" .Params.url | safeHTMLAttr }}>{{ default .Title .Params.heading }}</a></li>
                 {{ end }}
                 </ul>
             </nav>
diff --git a/layouts/index.html b/layouts/index.html
index be3a722..7d6252d 100644
--- a/layouts/index.html
+++ b/layouts/index.html
@@ -7,12 +7,12 @@
                     {{ .Content }}
                 </div>
             {{ end }}
-            {{ $totalpostscount := len (where .Data.Pages "Section" "blog") }}
+            {{ $totalpostscount := len (where .Site.RegularPages "Section" "==" "blog") }}
             {{ $latestpostscount := .Site.Params.latestpostscount | default $totalpostscount }}
             {{ if gt $latestpostscount 0 }}
                 <div class="page-heading">{{ i18n "latestPosts" }}</div>
                 <ul>
-                    {{ range (first $latestpostscount (where .Data.Pages.ByPublishDate.Reverse "Section" "blog")) }}
+                    {{ range (first $latestpostscount (where .Site.Pages.ByPublishDate.Reverse "Section" "blog")) }}
                         {{ partial "li.html" . }}
                     {{ end }}
                     {{ if gt $totalpostscount $latestpostscount }}
diff --git a/layouts/partials/head_includes.html b/layouts/partials/head_includes.html
index 3c21e39..24723e2 100644
--- a/layouts/partials/head_includes.html
+++ b/layouts/partials/head_includes.html
@@ -51,9 +51,9 @@
 >

 <!-- RSS -->
-{{ if .RSSLink }}
-  <link href="{{ .RSSLink }}" rel="alternate" type="application/rss+xml" title="{{ .Site.Title }}" />
-{{ end }}
+{{ with .OutputFormats.Get "rss" -}}
+    {{ printf `<link rel="%s" type="%s" href="%s" title="%s" />` .Rel .MediaType.Type .Permalink $.Site.Title | safeHTML }}
+{{ end -}}

 <!-- gitalk -->
 {{ if .Site.Params.gitalk }}
diff --git a/layouts/partials/staticman/form-comments.html b/layouts/partials/staticman/form-comments.html
index 91067df..544301c 100644
--- a/layouts/partials/staticman/form-comments.html
+++ b/layouts/partials/staticman/form-comments.html
@@ -1,6 +1,6 @@
 <form method="POST" action="https://api.staticman.net/v2/entry/{{ .Site.Params.staticman.username }}/{{ .Site.Params.staticman.repository }}/{{ .Site.Params.staticman.branch }}/">
     <input type="hidden" name="options[redirect]" value="{{ .Permalink }}#comment-submitted">
-    <input type="hidden" name="options[entryId]" value="{{ .UniqueID }}">
+    <input type="hidden" name="options[entryId]" value="{{ .File.UniqueID }}">
     <input name="fields[name]" type="text" placeholder="Your name">
     <input name="fields[email]" type="email" placeholder="Your email address">
     <textarea name="fields[body]" placeholder="Your message. Feel free to use Markdown." rows="10"></textarea>
diff --git a/layouts/partials/staticman/show-comments.html b/layouts/partials/staticman/show-comments.html
index bba3b5c..d7ff90e 100644
--- a/layouts/partials/staticman/show-comments.html
+++ b/layouts/partials/staticman/show-comments.html
@@ -1,6 +1,6 @@
  {{ $comments := readDir "data/comments" }}
  {{ $.Scratch.Add "hasComments" 0 }}
- {{ $entryId := .UniqueID }}
+ {{ $entryId := .File.UniqueID }}

  {{ range $comments }}
    {{ if eq .Name $entryId }}
#+END_SRC

** DONE Moving files on windows with python: shutil alternative
CLOSED: [2020-05-17 dom 11:20]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-05-17-moving-files-on-windows-with-python-shutil-alternative
:END:

Transfering data from my HD across a network, I have hit a bottleneck: the file
transfer speed was dramatically slow. In fact, the transfer took more time to finish than it took to generate the files. It was an unnaceptable situation due HD constraints.

It turns out that the file being copied to another partition is virtually
chunked, and each of them copied sequentialy. The more chunks the slower the
transfer is, while larger chunks increase memory usage [[https://superuser.com/questions/558292/how-does-copy-and-paste-for-large-files-work][[1]​]]. Iniatially I thought
I had to change the shutil module itself to make it work, so I avoided this
path [[https://stackoverflow.com/questions/21799210/python-copy-larger-file-too-slow][[2]​]].

The solution I came up, however, was switching to Windows Robust File Copy utility, or ~robocopy~. It has some perks, including showing the status of the
transfer on the command line, which was handy at this particular time. The
solution looks like the following:

#+BEGIN_SRC python
import time
import os

source = '\\source\\folder'
target = '\\target\\folder'

while True:
    for filename in os.listdir(source):
        os.system('Robocopy "%s" "%s" "%s" /MOV' %
                  (source, target, filename))
    time.sleep(300)
#+END_SRC

The python usage was only necessary to periodically move incoming files, keeping HD usage controlled.

#+BEGIN_QUOTE
**Attention:** Do not use ~/MOVE~ unless you want the folder structure to be
  moved as well. ~/MOV~ will keep the folder structure intact, moving only the
  files targeted.
#+END_QUOTE

Later I have found out you can manage to adjust buffer size directly
without modifying the source code directly [[https://blogs.blumetech.com/blumetechs-tech-blog/2011/05/faster-python-file-copy.html][[3]​]]. I will keep that in mind for the
next time.


** TODO Retrieving music sheet off midi visualizer in youtube videos using opencv part 1
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-15-retrieving-music-sheet-off-midi-visualizer-in-youtube-videos-using-opencv
:END:

#+begin_quote
TESTE
#+end_quote

I've been with [[https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj1qLa5jPrfAhUwHLkGHTNKBZsQyCkwAHoECAoQBQ&url=https%253A%252F%252Fwww.youtube.com%252Fwatch%253Fv%253DDXP1KdZX4io&usg=AOvVaw2fnmqyhFJpLHe0x4F84Fcj][Radiohead's man of war song]] stuck in my head for over a week. While browsing youtube and waiting eagerly for Josh Cohen's songbook to come out, I stumbled upon another gifted youtuber pianist called Alex Franklin. Franklin also happened to have covered this song. In case you are wondering, here are [[https://www.youtube.com/watch?v=M0GQtolLnEU][Josh's]] and [[https://www.youtube.com/watch?v=jTfhYBCrKyc][Alex's]] versions of the song. 

Anyways, I saw the midi visualizer on the top of the piano keys on Franklin's cover and thought "oh my, I would really love to have the piano sheet for this". So here I am, trying to recognize the key strokes from a video and translate it into a piano sheet.

This is the first part of a series of posts (out of as many as needed) where I will publish the milestones of this journey as someone unitiated in visual recognition. The focus of this post is just to recognize the keystrokes of the left and right hands from an screenshot. This will require me to:

- Select the right tools for the job;
- Setup the development environment
- Detect the keys being pressed
- Define which hand is responsible for the keystroke
- Define the which musical note was played
- Translate the note to musical notation

And of course, time and will to persevere. 

*** The tools

I chose python as a programming language for it's ubiquitous presence in machine learning projects. Also for affinity. Python also has pre-built version of the /de facto/ standard library for computational vision: [[https://opencv.org/][OpenCV]]. Alternatives were [[http://tutorial.simplecv.org/en/latest/][SimpleCV]] and [[https://scikit-image.org/][scikit-image]], however I wanted to try the most popular and powerful tool out there.

Keystrokes recognized it is time to engrave them in a beautiful sheet. The GNU Project has a program called [[http://lilypond.org/][LilyPond]], which deals exactly with this task. LilyPond files are text files that can be easily manipulated using a library such as [[https://python-ly.readthedocs.io/en/latest/][python-ly]] or even simpler as per [[https://www.python-course.eu/python_scores.php][this example]] using a simple correspondence map.

Docker to ease the pain. Reason in the next session.

*** The setup

OpenCV is written in C++ and I found it's installation everything but straightforward. Even with the excellent aid of [[https://www.pyimagesearch.com/2018/08/15/how-to-install-opencv-4-on-ubuntu/][Adrian Rosenbrock's tutorial]], I could not execute a simple:

#+begin_src python
import cv2
#+end_src

without a "ModuleNotFoundError: No module named 'cv2'". I tried many alternatives swith no success. This led me to download a Docker image and skip this problem altogether. The second image on dockerhub did the trick. The author Josip Janzic hosts it on github ([[https://github.com/janza/docker-python3-opencv][link here]]). It has a more recent version of python and opencv than the first image as of today's date. To get started just issue:

#+begin_src python
docker run -it jjanzic/docker-python3-opencv python
#+end_src

And a working environment with opencv installed will be downloaded from dockerhub if a local image is not present. Needless to say you need to have Docker installed.

Since I've made a minor modification in the original Dockerfile, I had to rebuild the image and renamed it for this project:

#+begin_src python
docker build -t vis_enc .
#+end_src

But nothing is perfect and while I was eager to try out some code, I got stuck with the following error:

#+begin_quote
cv2.error: OpenCV(4.0.0) /opencv-4.0.0/modules/highgui/src/window.cpp:625: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'
#+end_quote

Which led me to modify the Dockerfile yet again and rebuild the image.

*** Detecting keystrokes
Here's the screenshot used for this experiment:

#+caption: Piano keystrokes. In blue, right hand, in green the left hand.
#+name: bgkeys
[[/home/guilherme/blog/static/img/bgkeys.png]]
*Right hand in green and left hand in blue*

** TODO DS setup without admin rights on windows
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-04-05-ds-setuo-wo-admin-rights-windows
:END:
*** Strategy
Installing any program on "C:\Program Files", Windows default installation folder, requires admin rights. To bypass this, an easy workarround is to install programs on "HOME" folder. It is usually "C:\Users\yourusername\" and can be accessed by typing ~%HOME%~ on the address bar.

Many programs will work out just fine without any customization. However some programs will need to be set up in order to iteract with each other. The following list is a personal preference related to the tools realted to DS tasks I found easiest to setup without admin rights.
*** Alias
#+BEGIN_SRC cmd
@echo off

:: RESOURCES:
::
:: Curl download:
:: https://bintray.com/vszakats/generic/curl/
::
:: CMD aliases:
:: https://stackoverflow.com/questions/20530996/aliases-in-windows-command-prompt
:: You may make the alias(es) persistent with the following steps,
::
:: 1. Create a .bat or .cmd file with your DOSKEY commands.
:: 2. Run regedit and go to HKEY_CURRENT_USER\Software\Microsoft\Command Processor
:: 3. Add String Value entry with the name AutoRun and the full path of your .bat/.cmd file.
::
::  For example, %USERPROFILE%\alias.cmd, replacing the initial segment of the path with %USERPROFILE% is useful for :: syncing ::among multiple machines.
::
:: This way, every time cmd is run, the aliases are loaded.
::
:: Python download:
:: https://www.python.org/downloads/release/python-370/
:: Windows x86-64 executable installer
::
:: R and RSTudio:
:: https://rpubs.com/tomhopper/windows_nonadmin_install

:: Temporary system path at cmd startup

set PATH=%PATH%;

:: Commands

DOSKEY ls=dir /B
DOSKEY npp="C:\Users\guilhermetmcp\npp\notepad++.exe"
DOSKEY alias=notepad %USERPROFILE%\alias.cmd
DOSKEY vim="C:\Users\guilhermetmcp\Vim\vim81\gvim.exe"
DOSKEY mfe=cd "C:\Users\guilhermetmcp\mfe" ^& "venv\Scripts\activate"
DOSKEY qa=cd "C:\Users\guilhermetmcp\quality" ^& "venv\Scripts\activate"
DOSKEY va="venv\Scripts\activate"
DOSKEY vd="venv\Scripts\deactivate"

set curldir="C:\Users\guilhermetmcp\curl\bin\curl.exe"
set gitdir="C:\Users\guilhermetmcp\PortableGit\cmd"
set jupyterdir="C:\users\guilhermetmcp\appdata\local\programs\python\python37\Scripts"
set subldir="C:\Users\guilhermetmcp\Sublime"
set rcdir="C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64"
set bashesdir="C:\Users\guilhermetmcp\bashes"
set cmakedir="C:\Users\guilhermetmcp\cmake\bin"

set pythonpath="C:\Users\guilhermetmcp\AppData\Local\Programs\Python\Python37"
set pythonscripts="C:\Users\guilhermetmcp\AppData\Local\Programs\Python\Python37\Scripts"
set rdir="C:\Users\guilhermetmcp\R\R-3.5.1\bin"
set PATH=%curldir%;%gitdir%;%cmakedir%;%pythonpath%;%pythonscripts%;%subldir%;%rcdir%;%bashesdir%;%rdir%;%PATH%
#+END_SRC
*** Sublime
*** Git
*** R
*** RStudio
*** MikTex
Miktex has a portable edition.  Download it from [[https://miktex.org/download][MikTex download page]] and unzip it to you "HOME" folder. Once MikTex is there, it is time to make RStudio find it otherwise Sweaving documents to pdf will be unavailale.
*** Python
It is possible to download the excutable
**** Apache airflow
Apache airflow could not be installed without a admin rights. In fact it should, but I did not have Microsoft Visual C++ Build Tools in my system, as per the error below.

#+BEGIN_QUOTE
 error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/
#+END_QUOTE

However, having this sorted out was not enough. The following error plagued me:

#+BEGIN_QUOTE
error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\link.exe' failed with exit status 1158
#+END_QUOTE

Basically it meant that ~link.exe~ could not find ~rc.exe~ (go figure...). So I promptly inserted it in my alias path:

#+BEGIN_SRC cmd
set rcdir="C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64"
#+END_SRC

After all this process, the taste of success:

#+BEGIN_SRC sh
Installing collected packages: setproctitle, apache-airflow
Successfully installed apache-airflow-1.10.2 setproctitle-1.1.10
#+END_SRC

*** IPython

The first error was "ModuleNotFoundError: No module named 'ipykernel'", solved with ~pip install ipykernel~.


Ipython ~%matplotlib inline~ did not work out of the box. It threw an error ~No event loop integration for 'inline'. Supported event loops are: qt, qt4, qt5, gtk, gtk2, gtk3, tk, wx, pyglet, glut, osx~ related to the backend available to display the images.

To solve this error I just installed ~PyQt5~ via pip and issued ~%matplotlib qt~ as an alternative to ~inline~. Note it is necessary ot have the ~ipykernel~ also installed via pip prior to ~PyQt5~ installation.
* Footnotes
* COMMENT Local Variables                          :ARCHIVE:
# Local Variables:
# org-hugo-auto-export-on-save: t
# End:
