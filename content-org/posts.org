#+hugo_base_dir: /home/gtpedrosa/Projects/blog/hugo-blog/

* blog
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
** DONE Using org mode and ox-hugo to replace markdown in hugo workflow
CLOSED: [2019-01-13 dom 13:41]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-01-using-org-mode-and-ox-hugo-to-replace-markdown-in-hugo-workflow
:END:

I have decided to give org mode blogging a go. Why org mode? The main reasons for this were:

- Abandon markdown: I always get confused by markdown markup choices. I find myself constantly reaching for [[https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet][markdown cheatsheet]] to find out how to insert a link. "Is it parenthesis or brackets?" gets me every time;
- Increase familiarity with org mode synthax to use it in my literary programming workflows in the near future (tangle+babel);
- Reduce friction to create new blog posts using the great [[https://ox-hugo.scripter.co/][ox-hugo]] by Kaushal Modi.

For anyone trying to do the same, I recommend:

- [[https://www.kengrimes.com/ox-hugo-tutorial/][ox-hugo tutorial by Ken Grimes]]
- [[https://ox-hugo.scripter.co/][ox-hugo website/manual]]
- [[https://karl-voit.at/2017/09/23/orgmode-as-markup-only/][Some org mode markup notes and comments by Karl Voigt]]
- [[http://ergoemacs.org/emacs/emacs_org_markup.html][Most frequently used org mode markup by Xah]]

Since I want this post to be self contained for further reference in the near future, I will summarise what I've learned from the references above.

*** Installation and .emacs setup

#+begin_quote
*EDIT Apr 04 2020:* Instructions updated after noticing they failed in brand new system installation
#+end_quote

- Installation with package manager:
#+begin_src emacs-lisp
  M-x package-install RET ox-hugo RET
#+end_src
- Require it in the .emacs file:
#+begin_src org
  (with-eval-after-load 'ox__
    (require 'ox-hugo))
#+end_src
- To take advantage of auto exporting on save I added the following to my .emacs file:
#+begin_src org
  ;; Hugo orgmode exporter
  (require 'org-hugo-auto-export-mode) ;If you want the auto-exporting on file saves
#+end_src
- Enable snippets shortcuts
#+begin_src org
  (require 'org-tempo);Enable snippets expantions (ex: <s+TAB or <q+TAB)
#+end_src
- Now to create a capture template to create new blog postos on the fly:
#+begin_src org
  ;; Populates only the EXPORT_FILE_NAME property in the inserted headline.
  (with-eval-after-load 'org-capture
    (defun org-hugo-new-subtree-post-capture-template ()
      "Returns `org-capture' template string for new Hugo post.
  See `org-capture-templates' for more information."
      (let* ((title (read-from-minibuffer "Post Title: ")) ;Prompt to enter the post title
             (fname (org-hugo-slug title)))
        (mapconcat #'identity
                   `(
                     ,(concat "* TODO " title)
                     ":PROPERTIES:"
                     ,(concat ":EXPORT_FILE_NAME: " (format-time-string "%Y-%m-%d-") fname)
                     ":END:"
                     "%?\n")          ;Place the cursor here finally
                   "\n"))))

  ;; org capture templates
  (setq org-capture-templates
   '(
     ("h"                ;`org-capture' binding + h
                      "Hugo post"
                      entry
                      ;; It is assumed that below file is present in `org-directory'
                      ;; and that it has a "Blog Ideas" heading. It can even be a
                      ;; symlink pointing to the actual location of all-posts.org!
                      (file+olp "/home/guilherme/blog/content-org/posts.org" "blog")
                      (function org-hugo-new-subtree-post-capture-template))
  ))
#+end_src
- Include a /.dir-locals.el/ file in the project root, assuming all org-files are in a /content-org/ directory below root:
#+begin_src org
  (("content-org/"
    . ((org-mode . ((eval . (org-hugo-auto-export-mode)))))))
#+end_src

*Note:* everything here so far is in the manual. I only added the current date to the file name being created in the ~EXPORT_FILE_NAME:~ property to be consistent with my previous naming scheme.

*** Org file structure

Ken grimes did a great job explaining how to use one org file to organize a hugo blog. I'll just mention a few things. First of all, Hugo has a contents folder and depending on the theme you use (I use cocoa) it will have 

#+begin_src shell :exports both :results output
  tree -d -L 2 ../content
#+end_src

#+results: 
: ../content
: ├── about
: ├── blog
: └── projects
: 
: 3 directories



I haven't been using ox-hugo in my previous posts, so I already have markdown files that do not have a corresponding org version. However, my posts reside in the blog folder. As an example, a minimal org file used to generate this post would be the following:

#+begin_src org
  ,#+hugo_base_dir: /home/guilherme/blog/
   ,* blog
  :PROPERTIES:
  :EXPORT_HUGO_SECTION: blog
  :END:
   ,** TODO Using org mode and ox-hugo to replace markdown in hugo workflow
  :PROPERTIES:
  :EXPORT_FILE_NAME: 2019-01-01-using-org-mode-and-ox-hugo-to-replace-markdown-in-hugo-workflow
  :END:

   ,* Footnotes
   ,* COMMENT Local Variables                          :ARCHIVE:
   # Local Variables:
   # org-hugo-auto-export-on-save: t
   # End:
#+end_src

The local variable ~org-hugo-auto-export-on-save~ with the ARCHIVE tag enables hugo auto export to my blog's master org file only.

*** Workflow

To create a new blog post I simply issue ~C+c C+c + h~ and a title for my new post is prompted. Along with it the filename with date are already set by the property in the capture template. Form now on I just write. 

To view any changes on my working post:

#+begin_src bash
  hugo serve -D --navigateToChanged
#+end_src

When done with the post, just changing the task from TODO to DONE will create a special property date that will be the post's date published.

*** Markup examples
I've put together some markup examples that were spread through the sources mentioned in the beggining of the post. These are for quick lookups, where I can find the synthax for features I use the most.

#+caption: Same Org Logo
#+name: img__org_logo
[[file:/home/gtpedrosa/Projects/blog/hugo-blog/static/img/gnu-unicorn.png]]
*Here we refer to [[img__org_logo]].*

#+begin_quote
Everything should be made as simple as possible,
but not any simpler -- Albert Einstein
#+end_quote

#+begin_src org
  ,* This Is A Heading
  ,** This Is A Sub-Heading
  ,*** And A Sub-Sub-Heading

  Paragraphs are separated by at least one empty line.

  ,*bold* /italic/ _underlined_ +strikethrough+ =monospaced= ~code~
  [[http://Karl-Voit.at][Link description]]
  http://Karl-Voit.at → link without description

  : Simple pre-formatted text such as for source code.
  : This also respects the line breaks. *bold* is not bold here.

  - list item
  - another item
    - sub-item
      1. also enumerated
      2. if you like
  - [ ] yet to be done
  - [X] item which is done	
#+end_src

#+caption: Hello
#+name: code__hello
#+begin_src emacs-lisp
  (message "Hello")
#+end_src
*Here we refer to [[code__helloagain]].*

#+include: "./common.org::#lorem-ipsum" :only-contents t

#+caption: Hello Again
#+name: code__helloagain
#+begin_src emacs-lisp
  (message "Hello again")
#+end_src
*Here we refer to [[code__hello]].*
** DONE Generating documentation of Matlab scripts automatically with mkdocs
CLOSED: [2019-01-20 dom 23:06]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-20-generating-documentation-of-matlab-scripts-automatically-with-mkdocs
:END:

Something that always called my attention is how much more documented and even appealing to newcomers projects in python or R are if compared to Matlab in general. One exception is [[https://github.com/vlfeat/matconvnet][MatConvNet]], a library that implements convolutional neural networks (CNNs) in Matlab and has a good looking and helpful documentation. 

The documentation stands out as it is produced with [[https://www.mkdocs.org/][MkDocs]], a static site generator based on markdown specific for project documentation. Something very different from Matlab's default html help template. But why bother adding another layer of complexity writing markdown files for the documentation? Why not use the source code itself? The authors of MatConvNet created a parser capable of extracting the comments of the functions in mfiles and auto generate the markdown necessary for MkDocs. The python scripts ~matdoc.py~ and ~matdocparser.py~ do exactly that. I must acknowledge it is copywrited material (Copyright (c) 2014-16 The MatConvNet Team) and not made by me.

For the remaining of this post consider a simple project composed of two mfiles: ~addme.m~ and ~subtractme.m~ which do exactly what you would expect from them, add and subtract two numbers. Also consider a ~index.md~ and a ~mkdocs.yml~ file, the bare minimum for a MkDocs documentation. This is the files setup and they can be downloaded from my github [[https://github.com/gtpedrosa/matlab-mkdocs][here]].

#+begin_src shell :exports both :results output
  tree -L 2 ~/Sandbox/docs
#+end_src

#+results: 
#+begin_example
  /home/guilherme/Sandbox/docs
  ├── addme.m
  ├── COPYING
  ├── COPYING~
  ├── docs
  │   └── index.md
  ├── makefile
  ├── matdocparser.py
  ├── matdocparser.pyc
  ├── matdoc.py
  ├── mkdocs.yml
  └── subtractme.m

  1 directory, 10 files
#+end_example

The following make file is responsible for the automation of the pocess:

#+begin_src shell
  PYTHON = python2
  MKDOCS = mkdocs
  SRC = $(wildcard *.m)
  TAR = $(SRC:.m=.md)

  mfiledir = docs/mfiles

  $(info SRC is $(SRC))
  $(info TAR is $(TAR))
  $(info mfiledir is $(mfiledir))

  .PHONY: all clean

  all: $(TAR)

  %.md: %.m matdoc.py matdocparser.py
        $(info $(@))
        $(info $(@D))
        mkdir -p $(mfiledir)
        $(PYTHON) ./matdoc.py "$(<)" > "$(mfiledir)/$(@)"

  doc-serve: mkdocs.yml
        $(MKDOCS) serve

  clean:
        rm -f $(TAR)
        rm -rf $(mfiledir)
#+end_src

Issuing 

#+begin_src shell
  make all
  make doc-serve
#+end_src

This is the expected output:

#+results: 
#+begin_example
  SRC is subtractme.m addme.m
  TAR is subtractme.md addme.md
  mfiledir is docs/mfiles
  subtractme.md
  .
  mkdir -p docs/mfiles
  python2 ./matdoc.py "subtractme.m" > "docs/mfiles/subtractme.md"
  addme.md
  .
  mkdir -p docs/mfiles
  python2 ./matdoc.py "addme.m" > "docs/mfiles/addme.md"
  SRC is subtractme.m addme.m
  TAR is subtractme.md addme.md
  mfiledir is docs/mfiles

  INFO    -  Building documentation... 
  INFO    -  Cleaning site directory 
  [I 190120 22:44:13 server:283] Serving on http://127.0.0.1:8000
  [I 190120 22:44:13 handlers:60] Start watching changes
  [I 190120 22:44:13 handlers:62] Start detecting changes
  [I 190120 22:44:55 handlers:133] Browser Connected: http://localhost:8000/#project-layout
  [I 190120 22:44:55 handlers:133] Browser Connected: http://127.0.0.1:8000/
#+end_example

And finally, the end result, a home page based on the ~index.md~ file:

#+caption: MkDocs documentation generated automatically for a matlab project
#+name: mkdocsproject
[[file:/home/guilherme/blog/static/img/mkdocshome.png]]

And more importantly, automatic documentation for each function in a specific menu called ~M-files~:

#+caption: Documentation for each mfile
#+name: mkdocsfunctions
[[file:/home/guilherme/blog/static/img/mkdocsfunction.png]]

** DONE Using httr with JSON API's                                   :R:APIs:
CLOSED: [2019-03-24 dom 11:35]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-03-24-using-httr-with-json-api-s
:END:

It is incredbly easy to make R interact with external API's. I've found [[https://cran.r-project.org/web/packages/httr/vignettes/api-packages.html][the httr vignette]] to be a great resource on how to make a wrapper to interact with them. However I've stumbled in one quirk that is worth mentioning.

While creating a body to a POST request message, encoded with json, I verified that my requests were being turned down by the server. The issue was related  to a behavior of the ~jsonlite~ package, one of httr's dependencies which uses  ~auto_unbox=TRUE~ by default. This isn't an issue /per se/ but for length one vector jsonlite returned:

#+begin_src R :exports both :results output
  cat(jsonlite:::toJSON(list(message = "my string"),auto_unbox=T))
#+end_src

#+results: 
: {"message":"my string"}



Whereas the API requested a *boxed* response from length one vectors, such the one you get without the ~auto_unbox=TRUE~ option

#+begin_src R :exports both :results output
  cat(jsonlite:::toJSON(list(message = "my string")))
#+end_src

#+results: 
: {"message":["my string"]}



Reading [[https://github.com/r-lib/httr/issues/159][this github issue]] might give a more in depth explanation.

This led me to rabbit holes such as forking ~httr~ and recompiling with ~auto_unbox=FALSE~ option, which I did. But not without breaking other requests which truly needed to be unboxed.

The solution was simpler than I thought and makes use of the function ~AsIs~ from the base package. It can be called with the ~I(x)~ synthax and changes the class of an object indicating it should be treated /as is/. What this does is to prevent the ~auto_unbox~ behavior on certain fields where this is undesirable, such as in the following example: 

#+begin_src R :exports both :results output
  cat(jsonlite:::toJSON(list(message = "my string",mymessage = I("My other string")),auto_unbox=T))
#+end_src

#+results: 
: {"message":"my string","mymessage":["My other string"]}



This approach not only did not break anything but also made my requests compatible with the server boxed length one vectors specification as required.
** DONE Using SQLAlchemy to navigate an existing database :python:ORM:Databases:
CLOSED: [2019-04-06 sáb 18:56]
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-04-06-using-sqlalchemy-to-navigate-an-existing-database
:END:

Given the task to interact with an existing database I felt compelled to use the ORM abstraction instead of making queries with raw sql. My aim was to avoid the common pitfalls regarding making text templates for sqlqueries, prone to sql injection exploits, and enhance query composability. 

I've found there are essentialy two ways to approach this task: through reflextion or a declarative model. Both approaches are explained in the following sections.

*** SQLAlchemy reflection

Reflection uses metadata property to access schema constructs. It offers a few methods to access table objects, which do not have to be explicitly declared. 

The downside of this approach is mantainability, since schema changes can make code unreliable. Here's an eample of how to access the /TimeStamp/ column of a /Table_I_Want_to_Interact/ in a generic database:

#+begin_src python
  from sqlalchemy.orm import sessionmaker
  from sqlalchemy import create_engine, MetaData, Table

  # Using SQLAlchemy reflection example
  engine = create_engine('connectionstringhere')
  table1meta = MetaData(engine)
  table1 = Table('Table_I_Want_to_Interact', table1meta, autoload=True)
  DBSession = sessionmaker(bind=engine)
  session = DBSession()
  results = session.query(table1).filter(table1.columns.TimeStamp>="2019-02-26 18:00:00.000")
  results.all()
#+end_src

*** SQLAlchemy declarative model

The declarative model needs Table objects to be explicitly declared. Due to this inherent verbose nature, I have found it is easier to grasp what is happening and even how the database is structured after a glance at the source code, such as in the following snippet:

#+begin_src python
  from sqlalchemy import create_engine, MetaData, BigInteger, CHAR, Column, DateTime, Float, Integer, SmallInteger, String, Table, Unicode, text
  from sqlalchemy.ext.declarative import declarative_base
  from sqlalchemy.orm import sessionmaker

  Base = declarative_base()
  metadata = Base.metadata


  my_table_object = Table(
      'table_name', metadata,
      Column('Column1', Integer, nullable=False),
      Column('TimeStamp', DateTime, nullable=False),
      Column('Column3', Integer, nullable=False),
      Column('Column4', Unicode(2000))
  )
#+end_src

Here a table named /table_name/ in the database is being mapped to the /my_table_object/ instance. It should be noted that not all columns need to be mapped. Uninteresting columns can be left out with no drawbacks.

Depending on the database structure size, however,  it could be cumbersome to define multiple tables. For use cases like this, I have found the package [[https://pypi.org/project/sqlacodegen/][sqlacodegen]] of great help. It automates the task of creating the declarative models for you. Providing an output file and a connections tring it is as easy as issuing:

#+begin_src shell
  sqlcodegen --outfile models.py mssql+pyodbc......
#+end_src

The resulting file can be easily imported and the this task promptly abstracted.

** DONE Reading SQL Dumps with SQL Server management Studio   :sql:Databases:
CLOSED: [2020-04-12 dom 10:58]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-04-05-reading-sql-dumps-with-sql-management-studio
:END:

This post is about how to inspect the content of SQL database (/.mdf/ and /.ldf/ files). The answer is to attach these files to an existing SQL server instance, instead of opening them directly with a tool such as SQL Management Studio. This was not clear time until I stumbled upon [[https://www.youtube.com/watch?v=rhIr9Qf-oHw][this video.]]

*** Steps

1. Keep a SQL Server instance running in the background;
2. Fire up SQL Management studio and connect to this instance by providing /.\SQLEXPRESS/ in the "Server name" field;
3. Right click "Database" and attach the mdf file. The ldf is automatically included;

*** Attention points

To check #1 spin up /SQL Configuration Manager/ and look for **SQL Server
(SQLEXPRESS)** instance. It should be already running by default, as shown in
Figure 1.

#+caption: SQL Express running instance
#+name: img:sqlexpress
[[file:/home/gtpedrosa/Projects/blog/hugo-blog/static/img/sqlexpress.png]]

As for #2 make sure to login using the system credentials as shown in Figure 2.

#+caption: SQL Server login
#+name: img:sqlserver
[[file:/home/gtpedrosa/Projects/blog/hugo-blog/static/img/sqlserver.png]]

As for #3, if you are not admin the mdf file needs to be stored somewhere in the
 Public user profile so the SQLExpress instance is able to locate it.

** DONE Building Emacs from source                             :emacs:source:
CLOSED: [2020-04-11 sáb 10:59]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-04-10-building-emacs-from-source-instructions
:END:

Steps needed to install emacs locally, mantaining pre-existing installation intact. In the end you will two different versions of emacs running in your system.

- [[https://www.emacswiki.org/emacs/EmacsSnapshotAndDebian][Install dependencies:]]
#+begin_src bash
  sudo apt-get install autoconf automake libtool texinfo build-essential xorg-dev libgtk-3-dev libjpeg-dev libncurses5-dev libdbus-1-dev libgif-dev libtiff-dev libm17n-dev libpng-dev librsvg2-dev libotf-dev libgnutls28-dev libxml2-dev libxpm-dev
#+end_src
- [[https://www.gnu.org/software/emacs/download.html][Download emacs from a nearby mirror]]
- Extract downloaded file. In this case it is /emacs-26.3.tar.xz/, and go to the extracted folder:
#+begin_src bash
  cd ~/Downloads
  tar -xf emacs-26.3.tar.xz
  cd emacs-26.3.tar.xz
#+end_src
- Run /configure/ setting the prefix to the local folder in home directory:
#+begin_src bash
  ./configure --with-mailutils --prefix="${HOME}/local"
#+end_src
- Build the components and istall it:
#+begin_src bash
  make
  make install
#+end_src

To run it, issue:
#+begin_src bash
  /home/local/bin/emacs
#+end_src

The local installation, if any, should still work normally.

** DONE Upgrading an outdated Hugo template                            :hugo:
CLOSED: [2020-05-10 dom 18:04]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-05-10-upgrading-an-outdated-hugo-template
:END:

Recently, I wanted to restart blogging in a new machine. After installing the
latest hugo version at the time and pulling my git repo I soon realized:

1. Hugo version in which the blog was built was v0.31, whereas the current one
   was v0.68.1.
2. The cocoa development was abandonned and no updates were made to cope with
   hugo enhancements

Since I do like this theme and already had a fork of it I decided to try and
upgrade it by myself, even though I have no experience with the go programming
language or web development.

This post is to tell you how I went about it.

*** Finding where the errors come from

First of all, running the dated theme with new hugo raised the following errors:

#+caption: Running hugo serve on outdated template
#+name: oldtemplate
[[file:/home/gtpedrosa/Projects/blog/hugo-blog/static/img/hugo-warnings.png]]
*Hugo serve warnings on outdated template*

The first thing you may notice is that there is no mention to what part of the
template is raising the warnings being shown. To overcome this, I grepped the
offending structures and mapped which template files were triggering the
warnings:

#+caption: Finding out offending lines from hugo template
#+name: greptemplate
[[file:/home/gtpedrosa/Projects/blog/hugo-blog/static/img/hugo-warning-lines.png]]
*Hugo warning files and lines*

Just in case you are wondering here is a summary of the grep flags used:

- r or -R is recursive,
- n is line number, and
- w stands for match the whole word.

The next step involved fiddling with the source code and learning about each one of the errors.

*** Page.RSSLink is deprecated

I have found some github issues related to the matter, such as [[https://github.com/gohugoio/hugo/issues/4427][this one.]]
However, what solved my issue was to read the docs [[https://gohugo.io/templates/rss/][here]] and look how an up to dated
template should handle RSS. Replacing the bit using the /.RSSLink/ construct
with the snippet below solved the issue.

#+begin_src html
  {{ with .OutputFormats.Get "rss" -}}
      {{ printf `<link rel="%s" type="%s" href="%s" title="%s" />` .Rel .MediaType.Type .Permalink $.Site.Title | safeHTML }}
  {{ end -}}
#+end_src

*** Page.URL is deprecated

This error was easier to tackle. The warning gave a reasonable solution that
worked in my case. By replacing /Page.URL/ with /.Permalink/ everything worked
as expected. Note that there was some trial and error here since there are other
two other possible options according to the warning. I iterated until success.

*** Page.UniqueID is deprecated

Again the warning suggestion was spot on and replacing /.UniqueID/ with
/.File.UniqueID/ supressed the warning.

*** Most recent blog posts not showing on index.html

This was the trickiest to fix. I ended up reading a little bit about [[https://gohugo.io/templates/template-debugging/][how to
debug hugo templates.]] It so happens that after a couple of iterations printing
some of the variables in the /index.html/ file with the synthax

#+begin_src html
  {{ printf "%#v" .Permalink }}
#+end_src

I found out /.Data.Pages/ as not yielding the right ammount of posts.
Using /.Site.RegularPages/ did. I cannot find the exact resource which brought to
my attention the difference between the old and new hugo synthax, however, It is
agreeable that /.Data/ is too generic of a name for this use case.

*** Final result

As final result the theme is working without any warnings on hugo v0.68.1.

The changes applied to the theme are summarised by the git diff below. For more
reasonable view just check [[https://github.com/gtpedrosa/cocoa-hugo-theme][my fork of the cocoa-hugo theme.]]

#+begin_src shell :results output
  cd /home/gtpedrosa/Projects/blog/hugo-blog/themes/cocoa/
  git diff c6e7 434d
#+end_src

#+begin_src shell
  diff --git a/layouts/_default/list.html b/layouts/_default/list.html
  index b2348a1..4490e6c 100644
  --- a/layouts/_default/list.html
  +++ b/layouts/_default/list.html
  @@ -10,7 +10,7 @@
               <nav class="section-items">
                   <ul>
                   {{ range .ByWeight }}
  -                    <li><a {{ printf "href=%q" .URL | safeHTMLAttr }}>{{ default .Title .Params.heading }}</a></li>
  +                    <li><a {{ printf "href=%q" .Params.url | safeHTMLAttr }}>{{ default .Title .Params.heading }}</a></li>
                   {{ end }}
                   </ul>
               </nav>
  diff --git a/layouts/index.html b/layouts/index.html
  index be3a722..7d6252d 100644
  --- a/layouts/index.html
  +++ b/layouts/index.html
  @@ -7,12 +7,12 @@
                       {{ .Content }}
                   </div>
               {{ end }}
  -            {{ $totalpostscount := len (where .Data.Pages "Section" "blog") }}
  +            {{ $totalpostscount := len (where .Site.RegularPages "Section" "==" "blog") }}
               {{ $latestpostscount := .Site.Params.latestpostscount | default $totalpostscount }}
               {{ if gt $latestpostscount 0 }}
                   <div class="page-heading">{{ i18n "latestPosts" }}</div>
                   <ul>
  -                    {{ range (first $latestpostscount (where .Data.Pages.ByPublishDate.Reverse "Section" "blog")) }}
  +                    {{ range (first $latestpostscount (where .Site.Pages.ByPublishDate.Reverse "Section" "blog")) }}
                           {{ partial "li.html" . }}
                       {{ end }}
                       {{ if gt $totalpostscount $latestpostscount }}
  diff --git a/layouts/partials/head_includes.html b/layouts/partials/head_includes.html
  index 3c21e39..24723e2 100644
  --- a/layouts/partials/head_includes.html
  +++ b/layouts/partials/head_includes.html
  @@ -51,9 +51,9 @@
   >

   <!-- RSS -->
  -{{ if .RSSLink }}
  -  <link href="{{ .RSSLink }}" rel="alternate" type="application/rss+xml" title="{{ .Site.Title }}" />
  -{{ end }}
  +{{ with .OutputFormats.Get "rss" -}}
  +    {{ printf `<link rel="%s" type="%s" href="%s" title="%s" />` .Rel .MediaType.Type .Permalink $.Site.Title | safeHTML }}
  +{{ end -}}

   <!-- gitalk -->
   {{ if .Site.Params.gitalk }}
  diff --git a/layouts/partials/staticman/form-comments.html b/layouts/partials/staticman/form-comments.html
  index 91067df..544301c 100644
  --- a/layouts/partials/staticman/form-comments.html
  +++ b/layouts/partials/staticman/form-comments.html
  @@ -1,6 +1,6 @@
   <form method="POST" action="https://api.staticman.net/v2/entry/{{ .Site.Params.staticman.username }}/{{ .Site.Params.staticman.repository }}/{{ .Site.Params.staticman.branch }}/">
       <input type="hidden" name="options[redirect]" value="{{ .Permalink }}#comment-submitted">
  -    <input type="hidden" name="options[entryId]" value="{{ .UniqueID }}">
  +    <input type="hidden" name="options[entryId]" value="{{ .File.UniqueID }}">
       <input name="fields[name]" type="text" placeholder="Your name">
       <input name="fields[email]" type="email" placeholder="Your email address">
       <textarea name="fields[body]" placeholder="Your message. Feel free to use Markdown." rows="10"></textarea>
  diff --git a/layouts/partials/staticman/show-comments.html b/layouts/partials/staticman/show-comments.html
  index bba3b5c..d7ff90e 100644
  --- a/layouts/partials/staticman/show-comments.html
  +++ b/layouts/partials/staticman/show-comments.html
  @@ -1,6 +1,6 @@
    {{ $comments := readDir "data/comments" }}
    {{ $.Scratch.Add "hasComments" 0 }}
  - {{ $entryId := .UniqueID }}
  + {{ $entryId := .File.UniqueID }}

    {{ range $comments }}
      {{ if eq .Name $entryId }}
#+end_src

** DONE Moving files on windows with python: shutil alternative
CLOSED: [2020-05-17 dom 11:20]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-05-17-moving-files-on-windows-with-python-shutil-alternative
:END:

Transfering data from my HD across a network, I have hit a bottleneck: the file
transfer speed was dramatically slow. In fact, the transfer took more time to finish than it took to generate the files. It was an unnaceptable situation due HD constraints.

It turns out that the file being copied to another partition is virtually
chunked, and each of them copied sequentialy. The more chunks the slower the
transfer is, while larger chunks increase memory usage [[https://superuser.com/questions/558292/how-does-copy-and-paste-for-large-files-work][[1]​]]. Iniatially I thought
I had to change the shutil module itself to make it work, so I avoided this
path [[https://stackoverflow.com/questions/21799210/python-copy-larger-file-too-slow][[2]​]].

The solution I came up, however, was switching to Windows Robust File Copy utility, or ~robocopy~. It has some perks, including showing the status of the
transfer on the command line, which was handy at this particular time. The
solution looks like the following:

#+begin_src python
  import time
  import os

  source = '\\source\\folder'
  target = '\\target\\folder'

  while True:
      for filename in os.listdir(source):
          os.system('Robocopy "%s" "%s" "%s" /MOV' %
                    (source, target, filename))
      time.sleep(300)
#+end_src

The python usage was only necessary to periodically move incoming files, keeping HD usage controlled.

#+begin_quote
**Attention:** Do not use ~/MOVE~ unless you want the folder structure to be
  moved as well. ~/MOV~ will keep the folder structure intact, moving only the
  files targeted.
#+end_quote

Later I have found out you can manage to adjust buffer size directly
without modifying the source code directly [[https://blogs.blumetech.com/blumetechs-tech-blog/2011/05/faster-python-file-copy.html][[3]​]]. I will keep that in mind for the
next time.

** DONE Setting up a Data Science local environment without administrative rights on Windows :data:science:windows:R:Python:Git:editors:IDE:
CLOSED: [2020-06-07 dom 18:24]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-06-07-data-science-local-environment-without-administrative-rights-on-windows
:END:

Installing any program on ~C:\Program Files~, Windows default installation folder, requires administrative rights. It is possible, however, to install programs on the ~HOME~ folder without any special permissions. The default ~HOME~ path is set to ~C:\Users\yourusername\~ and can be accessed by typing ~%HOME%~ on the address bar. I have found this approach makes it possible to have some autonomy from the IT department without compromising security.

Using this approach, the softwares will run just fine without any customization. One caveat, however, is that some set up is needed in order to make them interact with one another properly. 

The following list is a personal preference related to the tools used to perform the data science tasks I found easiest to setup without administrative (admin) rights and how to make them work without any problems.

*** Softwares

The main softwares I use are listed below:

- **Languages:** I use R mainly for data exploration/prototyping and Python for solution development. Bear in mind, however, that you can get some mileage with R exclusively depending on the need;
- **Editors:** I have installed notepad++, vim, emacs and Sublime Text 3. I end up using notepad++ for quick inspections of files, emacs for orgmode exclusively and Sublime for all my Python needs;
- **IDEs:** Why an IDE if you have a bunch of editors you might ask. Well, I find the experience of using RStudio for data explorations using R very well streamlined. Packaging works, I can do literate programming and weave the code into reports that work as an engineering memorandum and a reference for my future self or present analysis results;
- **VCS:** Git, indispensable in the analysis workflow and necessary to expand the toolbox set by pulling packages;

*** Configuration
**** Portable Programs

[[https://www.sublimetext.com/3][Sublime Editor]], [[https://git-scm.com/download/win][Git]], [[https://cran.r-project.org/bin/windows/base/][R]], [[https://rstudio.com/products/rstudio/download/][RStudio]] and [[https://www.python.org/downloads/windows/][Python]] all have portable versions, which do not require any installation. If not, they allow you to proceed with the installation process selecting a folder of your choice, such as ~HOME~.

The downfall of this installation process is that none of the above programs will be on the system path, nor they will be available through the command line. Here is where the ~aliases.cmd~ comes in.

**** aliases.cmd

To make a program available system wide, it's path should be appended to the ~PATH~ variable. Unfortunately, doing this permanently is also a privileged operation. It is possible however, to append the new paths every time you start a terminal for instance. To accomplish this, you can take the following approach, borrowed from [[https://stackoverflow.com/questions/20530996/aliases-in-windows-command-prompt][this SO answer]]: 

1. Create a .bat or .cmd file with your DOSKEY commands.
2. Run regedit and go to HKEY_CURRENT_USER\Software\Microsoft\Command Processor
3. Add String Value entry with the name AutoRun and the full path of your .bat/.cmd file.
 
In my case, I have created a ~alias.cmd~ file in my ~HOME~ folder. The file is reproduced below:

   #+begin_src cmd
  @echo off

  :: Temporary system path at cmd startup

  set PATH=%PATH%;

  :: Commands

  DOSKEY ls=dir /B
  DOSKEY npp="C:\Users\yourusername\npp\notepad++.exe"
  DOSKEY alias=notepad %USERPROFILE%\alias.cmd
  DOSKEY vim="C:\Users\yourusername\Vim\vim81\gvim.exe"
  DOSKEY p1=cd "C:\Users\yourusername\p1" ^& "venv\Scripts\activate"
  DOSKEY va="venv\Scripts\activate"
  DOSKEY vd="venv\Scripts\deactivate"

  set curldir="C:\Users\yourusername\curl\bin\curl.exe"
  set gitdir="C:\Users\yourusername\PortableGit\cmd"
  set jupyterdir="C:\Users\yourusername\appdata\local\programs\python\python37\Scripts"
  set subldir="C:\Users\yourusername\Sublime"
  set rcdir="C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64"
  set bashesdir="C:\Users\yourusername\bashes"
  set cmakedir="C:\Users\yourusername\cmake\bin"

  set pythonpath="C:\Users\yourusername\AppData\Local\Programs\Python\Python37"
  set pythonscripts="C:\Users\yourusername\AppData\Local\Programs\Python\Python37\Scripts"
  set rdir="C:\Users\yourusername\R\R-3.5.1\bin"
  set PATH=%curldir%;%gitdir%;%cmakedir%;%pythonpath%;%pythonscripts%;%subldir%;%rcdir%;%bashesdir%;%rdir%;%PATH%
  #+end_src

Some interesting points about this configuration:

- Typing ~alias~ in the terminal brings me to the file above so I can tweak it easily;
- Part of my workflow with python relies on using virtual environments. I have a standardized name for my virtual environments which is ~venv~. Therefore, I alieased the actiavtion/deactivation from the project root to ~va~ and ~vd~. This works across all my projects;
- Usual projects received their own aliases, such as the ~p1~ example;
- Python, Git, curl and R could are appended to the system path;

Now, either running a new terminal or executing the software, you should feel no difference in usage regardless of how/where the tools were installed.

*** Failures

This blog post would not be complete if I did not talk about the things i could **not** get to work. 

**** WSL
I have previously used Windows Subsystem for Linux (WSL) with success for personal projects. In fact, I believe that the [[https://nickjanetakis.com/blog/a-linux-dev-environment-on-windows-with-wsl-docker-tmux-and-vscode][setup proposed]] by Nick Janetakis is great. However, even asking for a privileged user to install and enable the WSL, I could not get it running with my unprivileged user. 
**** Docker
Similarly to what happened to the WSL, I have also tried to make docker available without any success. It seemed that all the changes made by a privileged user did not persist when I tried to use the installed software with my unprivileged credentials. 
**** Apache airflow
Apache airflow could not be installed without a admin rights. 

In fact it should, but I did not have Microsoft Visual C++ Build Tools in my system, as per the error below.

#+begin_quote
error: Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": https://visualstudio.microsoft.com/downloads/
#+end_quote

Since it was not a pre requesite for my projects, I have not investigated any further.

**** MikTex
I still have not figured out how to properly set MikTex to R's path. Miktex has a portable edition that can be downloaded from [[https://miktex.org/download][MikTex download page]]. As of now, weaving documents to pdf are still unavailale in my system and will require further integration.

*** Closing Notes

This is a simple, yet useful standard of tools and ways of operating with them. It should be noted:

- I have not been working with tools for front-end, but did have npm installed recently to make slide decks with [[https://revealjs.com/][reveal.js]] using the same approach;
- My analysis are not really considered data-heavy. In the cases where they were more intensive, relying on libraries such as [[https://diskframe.com/][diskframe]] or caches worked fine;

Let me know if you managed to get WSL, docker or Miktex working, or have a set-up willing to share.
** DONE Enabling Frescobaldi MIDI output         :MIDI:lilypond:Frescobaldi:
CLOSED: [2020-06-21 dom 23:29]
:PROPERTIES:
:EXPORT_FILE_NAME: 2020-06-21-enabling-frescobaldi-midi-output
:END:

Trying to export a composition engraved with lilypond to MIDI, I have found out that it was not properly set up. The resulting MIDI was mute, even though I could see its contents using Audacity.

The solution lies in [[https://askubuntu.com/questions/463575/frescobaldi-midi-player-seems-to-be-working-fine-but-doesnt-produce-any-sound][this post]]. After installing a MIDI to Wave converter and player called timidity and starting its daemon:

#+BEGIN_SRC shell
sudo apt-get install timidity
sudo service timidity start
#+END_SRC

A /Timidity port 0/ should be available after refreshing Midi Settings as player output option in the /Edit > Preferences > Midi Settings/ in Frescobaldi.

** DONE Patterns in Circle of Fiths                     :music:theory:piano:
CLOSED: [2021-11-30 ter 21:09]
:PROPERTIES:
:EXPORT_FILE_NAME: 2021-11-30-patterns-in-circle-of-fiths
:END:

Last Sunday I decided to start (re)learning some music theory by myself. The objective was to learn the scales and the entrypoint for that was the circle of fiths. I don't know why, but I felt the need to hold the circle of fiths chart I was consulting in my own hands. So instead of printing it I made my own, and while I was at it I thought it would be cool if the inner circle could spin, so I made it likewise. Here's the outcome:

#+caption: Handmade circle of fiths
#+name: cof
[[file:~/Projects/blog/hugo-blog/static/img/circle_of_fiths.jpg]]
*Handmade circle of fiths chart*

The phisicality of it made me eager to play with this tool. Soon, I started gaining insights that might be obvious for a seasoned musician or someone who is proficient in theory. Nonetheless, here are some findings that I found amusing.

*** 1.Notes Interwined

Notice how by starting at **F**, it is possible to spot the following sequence: F_G_A_B. The underscores just mean that a not is missing (is skipped). The interesting part is that you can fill the gaps with another sequence: _C_D_E_, yielding the full sequence FCGDAEB. So 7/12 notes of the circle are easily spotted as the white notes on the piano. But what about the other 5/12?

*** 2.Accidental Simmetry

Well, if you pay close attention between **F** and **B** counterclockwise all notes have accidentals. Consider the sequence GDAEB, which are the notes of the circle clockwise after C. Now repeat them with a flat and you have found the remaining 5/12 notes from the circle!

*** 3.Identifying key from Key Signature

**** 3.1.Sharps

Add a semitone to the last sharp, or roughly add a note to it. For instance, what is the major key for a key signature with a single sharp (F#)? F+1=G.

**** 3.2.Flats

Drop the last flat. It does not work with the major key signature with only one flat, which is F. For instance **Bb** major has two flats: B and E. Drop the Eb (last flat in the signature) and you will have Bb itself.

*** 4.Sharps and Flats Relationship

Being a circle one could wonder whereas sharps and flats are interconnected. If we take a closer look at the sharps and flats sequences:

- **Sharps:** FCGDAEB
- **Flats:** BEADGCF

If you read the sharps backwards you get the flats! Also, the sharps are just the sequence of the circle of the fiths ranging from F to B clockwise. Just refer to the image and it is easy to verify. If you go counterclockwise from B to F you get the flats. 

*** 5.From Major to Minor and Vice-Versa

The major and minor scales can be obtained through the following interval composition:

- **Major:** TTSTT(TS)
- **Minor:** (TS)TTSTT

Here T stands for tone and S for semi-tone. The funny thing is, if you remove the last two intervals of a major scale (TS) and transfer it to the beginning of the remaining intervals (TTSTT) you get the minor scale formulation. This realization is even cooler in the circle itself:

#+caption: Spun inner circle of the circle of fiths
#+name: spuncof
[[file:~/Projects/blog/hugo-blog/static/img/circle_of_fiths_spun.jpg]]
*Spun inner circle*

Here if you spin the inner circle by 1,5 tones (3 notes) you arrive at the same configuration as the major scale. So to obtain the relative minor to a major scale remove 1,5 tones from it. To derive the major from the minor add 1,5 tones. Example: What is the relative minor for D major? B minor. Try to see it on a piano, it is way easier. Another example the other way: What is the relative major scale to C# minor? E major. 
** TODO Retrieving music sheet off midi visualizer in youtube videos using opencv part 1
:PROPERTIES:
:EXPORT_FILE_NAME: 2019-01-15-retrieving-music-sheet-off-midi-visualizer-in-youtube-videos-using-opencv
:END:

I've been with [[https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwj1qLa5jPrfAhUwHLkGHTNKBZsQyCkwAHoECAoQBQ&url=https%253A%252F%252Fwww.youtube.com%252Fwatch%253Fv%253DDXP1KdZX4io&usg=AOvVaw2fnmqyhFJpLHe0x4F84Fcj][Radiohead's man of war song]] stuck in my head for over a week. While browsing youtube and waiting eagerly for Josh Cohen's songbook to come out, I stumbled upon another gifted youtuber pianist called Alex Franklin. Franklin also happened to have covered this song. In case you are wondering, here are [[https://www.youtube.com/watch?v=M0GQtolLnEU][Josh's]] and [[https://www.youtube.com/watch?v=jTfhYBCrKyc][Alex's]] versions of the song. 

Anyways, I saw the midi visualizer on the top of the piano keys on Franklin's cover and thought "oh my, I would really love to have the piano sheet for this". So here I am, trying to recognize the key strokes from a video and translate it into a piano sheet.

This is the first part of a series of posts (out of as many as needed) where I will publish the milestones of this journey as someone unitiated in visual recognition. The focus of this post is just to recognize the keystrokes of the left and right hands from an screenshot. This will require me to:

- Select the right tools for the job;
- Setup the development environment
- Detect the keys being pressed
- Define which hand is responsible for the keystroke
- Define the which musical note was played
- Translate the note to musical notation

And of course, time and will to persevere. 

*** The tools

I chose python as a programming language for it's ubiquitous presence in machine learning projects. Also for affinity. Python also has pre-built version of the /de facto/ standard library for computational vision: [[https://opencv.org/][OpenCV]]. Alternatives were [[http://tutorial.simplecv.org/en/latest/][SimpleCV]] and [[https://scikit-image.org/][scikit-image]], however I wanted to try the most popular and powerful tool out there.

Keystrokes recognized it is time to engrave them in a beautiful sheet. The GNU Project has a program called [[http://lilypond.org/][LilyPond]], which deals exactly with this task. LilyPond files are text files that can be easily manipulated using a library such as [[https://python-ly.readthedocs.io/en/latest/][python-ly]] or even simpler as per [[https://www.python-course.eu/python_scores.php][this example]] using a simple correspondence map.

Docker to ease the pain. Reason in the next session.

*** The setup

OpenCV is written in C++ and I found it's installation everything but straightforward. Even with the excellent aid of [[https://www.pyimagesearch.com/2018/08/15/how-to-install-opencv-4-on-ubuntu/][Adrian Rosenbrock's tutorial]], I could not execute a simple:

#+begin_src python
  import cv2
#+end_src

without a "ModuleNotFoundError: No module named 'cv2'". I tried many alternatives swith no success. This led me to download a Docker image and skip this problem altogether. The second image on dockerhub did the trick. The author Josip Janzic hosts it on github ([[https://github.com/janza/docker-python3-opencv][link here]]). It has a more recent version of python and opencv than the first image as of today's date. To get started just issue:

#+begin_src python
  docker run -it jjanzic/docker-python3-opencv python
#+end_src

And a working environment with opencv installed will be downloaded from dockerhub if a local image is not present. Needless to say you need to have Docker installed.

Since I've made a minor modification in the original Dockerfile, I had to rebuild the image and renamed it for this project:

#+begin_src python
  docker build -t vis_enc .
#+end_src

But nothing is perfect and while I was eager to try out some code, I got stuck with the following error:

#+begin_quote
cv2.error: OpenCV(4.0.0) /opencv-4.0.0/modules/highgui/src/window.cpp:625: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'
#+end_quote

Which led me to modify the Dockerfile yet again and rebuild the image. The final image is available in my github profile.

*** Detecting keystrokes
Here's the screenshot used for this experiment:

#+caption: Piano keystrokes. In blue, right hand, in green the left hand.
#+name: bgkeys
[[file:/home/guilherme/blog/static/img/bgkeys.png]]
*Right hand in green and left hand in blue*
** Footnotes
* COMMENT Local Variables                :ARCHIVE:
# Local Variables:
# org-hugo-auto-export-on-save: t
# End:
